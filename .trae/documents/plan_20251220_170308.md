# Qwen2.5-7B卫健委公文规范微调方案

## 一、方案概述

本方案将使用QLoRA技术在本地N卡4070（显存27GB，内存32GB）上微调Qwen2.5-7B模型，注入卫健委公文规范，提升生成文书的格式与术语专业度。

## 二、技术选型

1. **微调方法**：QLoRA（Quantized Low-Rank Adaptation）
2. **模型**：Qwen2.5-7B
3. **硬件要求**：
   - GPU：NVIDIA RTX 4070（27GB显存）
   - CPU内存：32GB
   - 存储空间：至少50GB（用于存放模型和数据集）

## 三、实施步骤

### 1. 环境准备

**安装依赖**：
```bash
pip install -q -U transformers accelerate peft bitsandbytes datasets scipy torch==2.4.1
```

### 2. 数据准备

**数据集构建**：
- 收集卫健委公文规范文档
- 整理成指令微调格式：
  ```json
  [
    {
      "instruction": "撰写一份关于开展医疗机构专项检查的通知",
      "input": "",
      "output": "【卫健委公文内容】"
    },
    {
      "instruction": "起草一份关于加强传染病防控工作的通报",
      "input": "",
      "output": "【卫健委公文内容】"
    }
  ]
  ```

**数据增强**：
- 对现有公文进行改写
- 添加不同类型的公文（通知、通报、请示、批复等）
- 确保数据集覆盖各种卫健委工作场景

### 3. 模型准备

**下载模型**：
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B", trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B",
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
    trust_remote_code=True
)
```

### 4. QLoRA配置

**关键参数设置**：
```python
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=16,  # LoRA秩
    lora_alpha=32,  # LoRA缩放因子
    target_modules=[
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj",
        "lm_head"
    ],  # 目标模块
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

model = get_peft_model(model, lora_config)
model.print_trainable_parameters()
```

### 5. 微调训练

**训练脚本**：
```python
import torch
from transformers import TrainingArguments, Trainer
from datasets import load_dataset

# 加载数据集
dataset = load_dataset("json", data_files="health_commission_data.json")

# 预处理函数
def preprocess_function(examples):
    return tokenizer(
        f"<|im_start|>system\n你是一名专业的卫健委公文撰写专家，请严格按照公文规范格式和术语要求撰写文书。<|im_end|>\n<|im_start|>user\n{examples['instruction']}<|im_end|>\n<|im_start|>assistant\n{examples['output']}<|im_end|>",
        truncation=True,
        padding="max_length",
        max_length=2048
    )

# 预处理数据集
tokenized_dataset = dataset.map(preprocess_function, batched=True)

# 训练参数
training_args = TrainingArguments(
    output_dir="./qwen2.5-7b-health",
    per_device_train_batch_size=2,
    gradient_accumulation_steps=4,
    learning_rate=2e-5,
    num_train_epochs=3,
    logging_steps=10,
    save_strategy="epoch",
    fp16=True,
    remove_unused_columns=False
)

# 训练器
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    tokenizer=tokenizer
)

# 开始训练
trainer.train()
```

### 6. 模型评估与测试

**评估指标**：
- 文本生成质量
- 公文格式规范性
- 术语专业度
- 生成速度

**测试方法**：
```python
# 加载微调后的模型
from peft import AutoPeftModelForCausalLM

model = AutoPeftModelForCausalLM.from_pretrained(
    "./qwen2.5-7b-health",
    device_map="auto",
    trust_remote_code=True
)

# 生成测试
inputs = tokenizer(
    f"<|im_start|>system\n你是一名专业的卫健委公文撰写专家，请严格按照公文规范格式和术语要求撰写文书。<|im_end|>\n<|im_start|>user\n撰写一份关于开展医疗机构专项检查的通知<|im_end|>\n<|im_start|>assistant\n",
    return_tensors="pt"
).to("cuda")

outputs = model.generate(
    **inputs,
    max_new_tokens=1024,
    temperature=0.7,
    top_p=0.95
)

print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

## 四、关键优化策略

1. **内存优化**：
   - 使用4-bit量化减少显存占用
   - 梯度累积减少批量大小
   - 禁用梯度检查点

2. **训练效率优化**：
   - 使用Flash Attention 2加速训练
   - 调整学习率和训练步数
   - 合理设置梯度累积步数

3. **数据质量优化**：
   - 确保公文格式规范
   - 术语使用准确
   - 覆盖多种公文类型

## 五、预期效果

1. **格式规范**：生成的文书符合卫健委公文格式要求
2. **术语专业**：使用准确的医疗健康领域专业术语
3. **内容准确**：符合卫健委工作实际和政策要求
4. **生成高效**：在4070 GPU上能够高效生成文书

## 六、风险与应对

1. **内存不足**：
   - 降低批量大小
   - 增加梯度累积步数
   - 减小最大序列长度

2. **训练不稳定**：
   - 调整学习率
   - 增加训练轮次
   - 优化数据质量

3. **生成质量不佳**：
   - 增加数据集规模
   - 优化指令格式
   - 调整生成参数

## 七、后续工作

1. **模型部署**：将微调后的模型部署到生产环境
2. **持续优化**：根据实际使用反馈不断迭代优化
3. **多模态扩展**：支持生成包含表格、图表的复杂公文
4. **领域深化**：针对特定医疗领域（如传染病防控、医疗质量）进行进一步微调

## 八、所需文件

1. **微调脚本**：`finetune_qwen2.5-7b_health.py`
2. **数据集**：`health_commission_data.json`
3. **依赖文件**：`requirements.txt`

## 九、运行命令

```bash
python finetune_qwen2.5-7b_health.py
```

本方案充分考虑了本地N卡4070的硬件限制，使用QLoRA技术实现高效微调，能够在有限的显存下成功注入卫健委公文规范，显著提升生成文书的格式与术语专业度。